{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before any other code cell\n",
    "# This downloads the csv data files into the same directory where you have saved this notebook\n",
    "\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "path = Path()\n",
    "\n",
    "# Dictionary of file names and download links\n",
    "files = {'Auto.csv':'https://storage.googleapis.com/aipi_datasets/Auto.csv'}\n",
    "\n",
    "# Download each file\n",
    "for key,value in files.items():\n",
    "    filename = path/key\n",
    "    url = value\n",
    "    # If the file does not already exist in the directory, download it\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    # Read in data\n",
    "    data = pd.read_csv(filename)\n",
    "    # Remove rows with missing values\n",
    "    data = data[data['horsepower'] != '?'].copy()\n",
    "    return data\n",
    "\n",
    "data = load_data('Auto.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Regression\n",
    "Let's use LASSO Regression to add regularization and see what impact it has on the features included in the model.  First we will run a standard linear regression to get a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data_allfeats(data,pct):\n",
    "    # Define the features and response (X and y)\n",
    "    X = data[['cylinders','displacement','horsepower','weight','acceleration','year']].copy().astype(int)\n",
    "    y = data['mpg'].copy().astype(float)\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=pct)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "\n",
    "# Split our data\n",
    "X_train,X_test,y_train,y_test = prep_data_allfeats(data,pct=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a LASSO model.  First we need to scale our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso(X_train,y_train,alpha=1.):\n",
    "    # First we scale our data - remember, only use the training data to fit the scaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # Run a LASSO model\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train_scaled,y_train)\n",
    "    return scaler,lasso_model\n",
    "\n",
    "def test_model(model, X_test, y_test,transform=None):\n",
    "    # Compute the MSE for a model\n",
    "    if transform is not None:\n",
    "        X_test = transform.transform(X_test)\n",
    "    preds = model.predict(X_test)\n",
    "    mse = 1/len(y_test)*np.sum((preds-y_test)**2)\n",
    "    return mse\n",
    "    \n",
    "scaler,model = train_lasso(X_train,y_train)\n",
    "test_mse = test_model(model, X_test, y_test,transform=scaler)\n",
    "print('MSE on the test set is {:.3f}'.format(test_mse))\n",
    "\n",
    "# Display the equation for the LASSO model\n",
    "coef = model.coef_\n",
    "intercept = model.intercept_\n",
    "equation = 'y = {:.3f} + '.format(intercept) + ' + '.join(['{:.3f}*{}'.format(coef,var) for coef,var in zip(coef,X_train.columns)])\n",
    "print(equation)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.barh(X_train.columns,coef)\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, our LASSO model at lambda/alpha=1.0 zeroed out several of our model coefficients, leaving only weight, horsepower, and year in our model.\n",
    "\n",
    "Let's look for the optimal value of the lambda (alpha) hyperparameter.  Since the possible range of values for lambda is 0 to infinity, let's start with a big picture analysis and then zoom in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_regularization(X_train,y_train,model,alpha_vals,nsplits=10):\n",
    "    '''\n",
    "    Finds the optimal value of alpha/lambda from a given range using cross-validation\n",
    "\n",
    "    Inputs:\n",
    "        X_train(pd.DataFrame): training set inputs\n",
    "        y_train(pd.Series): training set labels\n",
    "        model(sklearn.base.BaseEstimator): instantiated scikit-learn model object\n",
    "        alpha_vals(list): list of values to evaluate for alpha/lambda\n",
    "        nsplits(int): number of folds for cross-validation\n",
    "\n",
    "    Returns:\n",
    "        opt_lambda(float): alpha/lambda value from the input list that results in best cross-validation performance\n",
    "        errors(list): list of mean MSE across validation folds for each value of alpha/lambda\n",
    "    '''\n",
    "\n",
    "    ### BEGIN SOLUTION ####\n",
    "\n",
    "    \n",
    "\n",
    "    ### END SOLUTION ###\n",
    "\n",
    "\n",
    "# Now let's vary the lambda (alpha) hyperparameter and find the optimal value using cross-validation\n",
    "alpha_vals = [10**i for i in range(-3,3,1)]\n",
    "model = Lasso()\n",
    "opt_alpha, errors = optimize_regularization(X_train,y_train,model,alpha_vals,nsplits=10)\n",
    "    \n",
    "# Plot the mse vs lambda/alpha values, using log scale for lambda values\n",
    "plt.plot(np.log(alpha_vals),errors)\n",
    "plt.xticks(ticks=np.log(alpha_vals),labels=alpha_vals)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's zoom in to identify the optimal lambda value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vals = np.arange(0.,1.01,0.01)\n",
    "opt_alpha, errors = optimize_regularization(X_train,y_train,model,alpha_vals,nsplits=10)\n",
    "\n",
    "print('Optimal lambda value is {:.3f}'.format(opt_alpha))\n",
    "    \n",
    "# Plot the mse vs lambda/alpha values\n",
    "plt.plot(alpha_vals,errors)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on what we learned in the lecture, why might higher penalty values for the LASSO not work well in this particular case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's vary the lambda (alpha) hyperparameter and visualize the change in coefficients\n",
    "coeff_vals = {var:[] for var in X_train.columns} # Dict to hold values of each coefficient\n",
    "\n",
    "alpha_vals = np.arange(0.,5.01,0.1)\n",
    "for val in alpha_vals:\n",
    "    scaler,lasso_model = train_lasso(X_train,y_train,alpha=val)\n",
    "    coef = lasso_model.coef_\n",
    "    for coef,var in zip(coef,X_train.columns):\n",
    "        coeff_vals[var].append(coef)\n",
    "        \n",
    "# Plot the coefficient values\n",
    "plt.figure(figsize=(8,8))\n",
    "for var in coeff_vals.keys():\n",
    "    plt.plot(alpha_vals,coeff_vals[var],label=var)\n",
    "plt.plot([0,np.max(alpha_vals)],[0,0],color='black')\n",
    "plt.xlim(0,np.max(alpha_vals))\n",
    "plt.legend()\n",
    "plt.xlabel('lambda')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of the model with the optimized alpha/lambda\n",
    "scaler,model = train_lasso(X_train,y_train,alpha=opt_alpha)\n",
    "test_mse = test_model(model, X_test, y_test, transform=scaler)\n",
    "print('MSE on the test set is {:.3f}'.format(test_mse))\n",
    "\n",
    "# Display the equation for the LASSO model\n",
    "coef = model.coef_\n",
    "intercept = model.intercept_\n",
    "equation = 'y = {:.3f} + '.format(intercept) + ' + '.join(['{:.3f}*{}'.format(coef,var) for coef,var in zip(coef,X_train.columns)])\n",
    "print(equation)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.barh(X_train.columns,coef)\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ridge(X_train,y_train,alpha=1.0):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Run a Ridge model using the default lambda (alpha)\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "    ridge_model.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    return scaler, ridge_model\n",
    "\n",
    "scaler,model = train_ridge(X_train,y_train)\n",
    "test_mse = test_model(model, X_test, y_test, transform=scaler)\n",
    "print('MSE on the test set is {:.3f}'.format(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's vary the lambda (alpha) hyperparameter and find the optimal value using cross-validation\n",
    "alpha_vals = [10**i for i in range(-3,3,1)]\n",
    "model = Ridge()\n",
    "opt_alpha_ridge, errors = optimize_regularization(X_train,y_train,model,alpha_vals,nsplits=10)\n",
    "print('Of the values evaluated, the optimal lambda value is {:.3f}'.format(opt_alpha_ridge))\n",
    "    \n",
    "# Plot the mse vs lambda/alpha values\n",
    "plt.plot(np.log(alpha_vals),errors)\n",
    "plt.xticks(ticks=np.log(alpha_vals),labels=alpha_vals)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's vary the lambda (alpha) hyperparameter and find the optimal value using cross-validation\n",
    "alpha_vals = np.arange(0.,5.01,0.1)\n",
    "model = Ridge()\n",
    "opt_alpha_ridge, errors = optimize_regularization(X_train,y_train,model,alpha_vals,nsplits=10)\n",
    "print('Of the values evaluated, the optimal lambda value is {:.3f}'.format(opt_alpha_ridge))\n",
    "    \n",
    "# Plot the mse vs lambda/alpha values\n",
    "plt.plot(alpha_vals,errors)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('mse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's vary the lambda (alpha) hyperparameter and visualize the change in coefficients\n",
    "coeff_vals = {var:[] for var in X_train.columns} # Dict to hold values of each coefficient\n",
    "\n",
    "alpha_vals = np.arange(0.,5.05,0.05)\n",
    "for val in alpha_vals:\n",
    "    scaler,model = train_ridge(X_train,y_train,val)\n",
    "    # Get coefficients to plot\n",
    "    coef = model.coef_\n",
    "    for coef,var in zip(coef,X_train.columns):\n",
    "        coeff_vals[var].append(coef)\n",
    "        \n",
    "# Plot the coefficient values\n",
    "plt.figure(figsize=(8,8))\n",
    "for var in coeff_vals.keys():\n",
    "    plt.plot(alpha_vals,coeff_vals[var],label=var)\n",
    "plt.plot([0,np.max(alpha_vals)],[0,0],color='black')\n",
    "plt.xlim(0,np.max(alpha_vals))\n",
    "plt.legend()\n",
    "plt.xlabel('lambda')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of the model with the optimized alpha/lambda\n",
    "scaler,model = train_ridge(X_train,y_train,alpha=opt_alpha)\n",
    "test_mse = test_model(model, X_test, y_test, transform=scaler)\n",
    "print('MSE on the test set is {:.3f}'.format(test_mse))\n",
    "\n",
    "# Display the equation for the LASSO model\n",
    "coef = model.coef_\n",
    "intercept = model.intercept_\n",
    "equation = 'y = {:.3f} + '.format(intercept) + ' + '.join(['{:.3f}*{}'.format(coef,var) for coef,var in zip(coef,X_train.columns)])\n",
    "print(equation)\n",
    "\n",
    "# Plot the coefficients\n",
    "plt.barh(X_train.columns,coef)\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('aipi540')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31cc86d7aac4849c7546154c9b56d60163d5e8a1d83593a5eed18774fbf4fd37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
